{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ön İşleme (Preprocessing) ve Frekans Bulma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kütüphaneleri dahil edelim\n",
    "`nltk`: NLTK(Natural Language Toolkit(Doğal Dil Kiti)), insan dili verileriyle çalışmak için Pyhton ile geliştirilmiş açık kaynaklı bir kütüphanedir.\n",
    "\n",
    "`getcwd`: Dosyanın çalıştığı adresi getirir\n",
    "\n",
    "`numpy`: Numerical Python, çok boyutlu dizilerle ve matrislerle çalışmamızı sağlayan ve matematiksel işlemler yapabileceğimiz Python dili kütüphanelerindendir. \n",
    "\n",
    "`pandas`: Veri işlemesi ve analizi için Python ile yazılmış olan bir kütüphanedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from os import getcwd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import twitter_samples \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet örneklerini ve stopwordleri indirelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/macbookair/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/macbookair/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veri Seti\n",
    "İndirdiğimiz veri seti 5000 olumlu 5000 olumsuz tweet içeriyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tum_poz_tweetler = twitter_samples.strings('positive_tweets.json')\n",
    "tum_neg_tweetler = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıdaki kod parçacığı sayesinde çalışma alanımızı yenilediğimizde  dosyaları tekrar indirmeden içe aktarılmasını sağlarız"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dosyaAdr = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(dosyaAdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oluşturacağımız fonksiyonlar:\n",
    "* `tweet_isle()`: Metni temizleyip, kelimelere ayırıp (tokenization), stopwordleri kaldırıp, kökleme (stemming) yapacağımız fonksiyon. Yani tüm ön işleme burada olacak.\n",
    "* `frekans_olustur()`: Kelimelerin olumlu/olumsuz tweetlerdeki frekanslarını hesaplayacağımız fonksiyon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_isle(tweet):\n",
    "    # Girdi olarak islenmemis bir tweet aliyoruz\n",
    "\n",
    "    # Hashtagleri, linkleri vb. ibareleri tweetten temizliyoruz\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tweet = re.sub(r':()', '', tweet)\n",
    "    \n",
    "    # Metni kelimelere ayiriyoruz\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweetin_kelimeleri = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    ing_stopwordler = stopwords.words('english')\n",
    "    \n",
    "    # Sonucu dondurecegimiz diziyi bos olarak olusturuyoruz\n",
    "    islenmis_tweet = []\n",
    "    \n",
    "    for kelime in tweetin_kelimeleri:\n",
    "        if (kelime not in ing_stopwordler and kelime not in string.punctuation and not bool(re.search(r'\\d', kelime))):  \n",
    "            # Kelime stopword veya noktalama isareti degilse ve rakam icermiyorsa:\n",
    "            kelime_koku = PorterStemmer().stem(kelime)  \n",
    "            # Kokleme yapiliyor ve diziye ekleniyor\n",
    "            islenmis_tweet.append(kelime_koku)\n",
    "\n",
    "    return islenmis_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### İlk fonksiyonu deneyelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bir pozitif cumle: \n",
      " OMG so I did some math and if my channel continues like this (i doubt  it) I will get 2 300 subs when my 200 subs video comes out :) :/\n",
      "\n",
      "Pozitif cumlenin islenmis hali: \n",
      " ['omg', 'math', 'channel', 'continu', 'like', 'doubt', 'get', 'sub', 'sub', 'video', 'come']\n"
     ]
    }
   ],
   "source": [
    "print('Bir pozitif cumle: \\n', tum_poz_tweetler[1300])\n",
    "print('\\nPozitif cumlenin islenmis hali: \\n', tweet_isle(tum_poz_tweetler[1300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frekans_olustur(tweetler, duygular):\n",
    "    # Input olarak tweetler ve duygularini aliyoruz\n",
    "    # Duygu etiketlerini list haline getiriyoruz\n",
    "    duygu_listesi = np.squeeze(duygular).tolist()\n",
    "\n",
    "    # Kelimenin hangi duygudaki kelimede gectigine gore frekansini bir arttiriyoruz\n",
    "    frekanslar = {}\n",
    "    for duygu, tweet in zip(duygu_listesi, tweetler):\n",
    "        for kelime in tweet_isle(tweet):\n",
    "            ikili = (kelime, duygu)\n",
    "            if ikili in frekanslar:\n",
    "                frekanslar[ikili] += 1\n",
    "            else:\n",
    "                frekanslar[ikili] = 1\n",
    "\n",
    "    return frekanslar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### İkinci fonksiyonu deneyelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tum_tweetler = tum_poz_tweetler + tum_neg_tweetler\n",
    "\n",
    "duygular = np.append(np.ones((5000, 1)), np.zeros((5000, 1)), axis=0)\n",
    "\n",
    "frekanslar = frekans_olustur(tum_tweetler, duygular)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Rain' kelimesi olumlu cumlelerde  21  defa gecmis.\n",
      "'Rain' kelimesi olumsuz cumlelerde  43  defa gecmis.\n"
     ]
    }
   ],
   "source": [
    "print( \"'Rain' kelimesi olumlu cumlelerde \" , frekanslar.get((\"rain\", 1.0),0) , \" defa gecmis.\")\n",
    "print( \"'Rain' kelimesi olumsuz cumlelerde \", frekanslar.get((\"rain\", 0.0),0),\" defa gecmis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hope' kelimesi olumlu cumlelerde  141  defa gecmis.\n",
      "'Hope' kelimesi olumsuz cumlelerde  102  defa gecmis.\n"
     ]
    }
   ],
   "source": [
    "print( \"'Hope' kelimesi olumlu cumlelerde \", frekanslar.get((\"hope\", 1.0),0),\" defa gecmis.\")\n",
    "print( \"'Hope' kelimesi olumsuz cumlelerde \", frekanslar.get((\"hope\", 0.0),0),\" defa gecmis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
